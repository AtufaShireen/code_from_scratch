{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The decision tree can be used when the data is not linearly separable.\n",
    "2. We start with root node and split the tree until we get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index, threshold, left, right, info_gain, value) -> None:\n",
    "        # for decision node\n",
    "        self.feature_index  = feature_index\n",
    "        self. threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_sample_split, max_depth ) -> None:\n",
    "        self.root = None\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def get_best_split(self):\n",
    "        pass\n",
    "\n",
    "    def build_tree(self,dataset, curr_depth=0):\n",
    "        X,Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features =  np.shape(X)\n",
    "        if num_samples >= self.min_sample_split and curr_depth<=self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
